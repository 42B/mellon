#ScrapySettings
# Configure Python scrapy app runtime behavior.  See 
# https://doc.scrapy.org/en/latest/topics/settings.html for available
# settings that can be used
ScrapySettings:
 SETTING_ONE: VALUE_ONE
 SETTING_TWO: VALUE_TWO

#ScrapyFormData
# A very basic method to identify html form fields and their values.  field
# names and values are arbitrary to your needs
ScrapyFormData: &form_data
 field_1: data_1
 field_2: data_2

#ScrapySimpleTextWebsiteCrawler
# A minimalist configuration of a scrapy.spiders.CrawlSpider.  Provides
# information needed to create a basic CrawlSpider.  This is 
# intended to be used to help satisfy the basic use-case of look at a site's
# text contents (e.g. HTML markup removed).  Links to external sites will not
# be crawled.
#
# 
#
# features:
#  - CrawlSpider name will be domain name of the first url entry
#  - allowed_domains will be the domains of all entries
#  - start_urls will be the list of urls
ScrapySimpleTextWebsiteCrawler:
 urls:
  - http://sample1.url.com/login.php
  - https://sample2.url.com/start_page.htm
 ScrapyFormData: *form_data #optional auth information if url is a form-based auth processor
 ScrapySettings: *reference #optional
 RulesListFactory: python.module.callable #optional, Python callable that produces list of Rules 
 attributes: #optional
  attribute_1: value_1
  attribute_2:
   - value_2
   - value_3
  